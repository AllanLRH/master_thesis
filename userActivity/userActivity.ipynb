{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore') \n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use(\"bmh\")\n",
    "%matplotlib inline\n",
    "import missingno as msno\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "from scipy.optimize import leastsq\n",
    "\n",
    "from speclib.userActivityFunctions import getComdataMean\n",
    "from speclib.loaders import loadUserPhonenumberDict, getUserList, Useralias, loadUserParallel, dict2DataFrame, users2DataFrame\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare to load users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userLst = getUserList() \n",
    "useralias = Useralias() \n",
    "userSpec = [(username, useralias[username], ('call', 'sms')) for username in userLst]\n",
    "for el in userSpec[:10]:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = loadUserParallel(userSpec, n=15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn loaded user data into a DateFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = users2DataFrame(users, useralias, processes=15) \n",
    "del users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df.head(), df.tail()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently there is messages with no recieving number…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = df.loc[\"u0645\", \"sms\"].body == \"cc0bf55fbc000c9ffa5ca348a1724744ae704ae0\"\n",
    "\n",
    "df.loc[\"u0645\", \"sms\"][idx] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some plotting \n",
    "\n",
    "Plot activity for all users calls and sms' side by side. Each category sums up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "callWeek = df.xs('call', level=1).weekday.value_counts()\n",
    "callWeek /= callWeek.sum()\n",
    "smsWeek = df.xs('sms', level=1).weekday.value_counts()\n",
    "smsWeek /= smsWeek.sum() \n",
    "fig, ax = plt.subplots(figsize=(16, 6)) \n",
    "d0 = {'y': smsWeek.sort_index(), 'label': 'SMS'} \n",
    "d1 = {'y': callWeek.sort_index(), 'label': 'Call'} \n",
    "barSBS(ax, d0, d1) \n",
    "ax.set_ylabel(\"Fractional normalized activity\") \n",
    "ax.set_xticks(np.arange(0, 7) + 0.35) \n",
    "ax.set_xticklabels( (\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"), rotation=45 );\n",
    "ax.set_xlim((-0.05, 6.8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index into a sublevel of the MultiIndex like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sms = df.xs('sms', level=1)\n",
    "display(sms.head(), sms.tail()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call = df.xs('call', level=1).hour.value_counts()\n",
    "call /= call.sum()\n",
    "sms = df.xs('sms', level=1).hour.value_counts()\n",
    "sms /= sms.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6)) \n",
    "d0 = {'y': sms.sort_index(), 'label': 'SMS'} \n",
    "d1 = {'y': call.sort_index(), 'label': 'Call'} \n",
    "barSBS(ax, d0, d1) \n",
    "ax.set_ylabel(\"Fractional normalized activity\") \n",
    "ax.set_xlabel(\"Hour of day\") \n",
    "ax.set_xticks(np.arange(0, 24, dtype=np.int) + 0.35)\n",
    "ax.set_xticklabels([\"%d\"%i for i in range(24)])\n",
    "ax.set_xlim((-0.15, 23.89)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of times each uses calls or writes each unique phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'comFreq.pandasPickle' in os.listdir('.'):\n",
    "    comFreq = pd.read_pickle('comFreq.pandasPickle')  # Computation is slow\n",
    "else:\n",
    "    comFreq = pd.DataFrame(index=df.index.get_level_values('user').unique(), columns=('sms', 'call'))\n",
    "    comFreq.columns.name = 'comtype'\n",
    "    for user in df.index.get_level_values('user').unique():\n",
    "        for comtype in df.loc[user].index.unique():\n",
    "            comFreq.loc[user, comtype] = df.loc[user, comtype].number.value_counts().values\n",
    "    counterLambda = lambda x: 0 if np.any(pd.isnull(x)) else x.size\n",
    "    comFreq['smsUnique'] = comFreq.sms.apply(counterLambda)\n",
    "    comFreq['callUnique'] = comFreq.call.apply(counterLambda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comFreq.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6)) \n",
    "nMaxEvents = 250\n",
    "meanColor = '#d64413'\n",
    "for user in comFreq.index:\n",
    "    try:\n",
    "        ax.semilogy(comFreq.loc[user].call[:nMaxEvents], 'k-', alpha=0.04)\n",
    "    except TypeError:  # length-1 elements are apparently turned into floats, which isn't subscriptable\n",
    "        ax.semilogy(comFreq.loc[user].call, 'k-', alpha=0.04)\n",
    "ax.grid(which='minor')\n",
    "ax.semilogy(getComdataMean(comFreq, 'call', 'callUnique')[:nMaxEvents], color=meanColor, label='Mean signal') \n",
    "ax.set_xlabel('Call #')\n",
    "ax.set_ylabel(\"Number of calls to number\")\n",
    "ax.set_title(\"Communication from calls\")\n",
    "ax.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6)) \n",
    "nMaxEvents = 250\n",
    "meanColor = '#d64413'\n",
    "for user in comFreq.index:\n",
    "    try:\n",
    "        ax.semilogy(comFreq.loc[user].sms[:nMaxEvents], 'k-', alpha=0.04)\n",
    "    except TypeError:  # length-1 elements are apparently turned into floats, which isn't subscriptable\n",
    "        ax.semilogy(comFreq.loc[user].sms, 'k-', alpha=0.04)\n",
    "ax.grid(which='minor')\n",
    "ax.semilogy(getComdataMean(comFreq, 'sms', 'smsUnique')[:nMaxEvents], color=meanColor, label=\"Mean signal\") \n",
    "ax.set_xlabel('SMS #')\n",
    "ax.set_ylabel(\"Number of SMS' to number\")\n",
    "ax.set_title(\"Communication from SMS'\")\n",
    "ax.legend() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt a fit of the data, as I suspect it could be fittet well with a powerlaw.\n",
    "\n",
    "While the fit did converge, I'm not convinced that it's better than my own guess… are the results weighted towards the lower end, or something like that? Or did my algorithm just converge on a local minima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut = 4\n",
    "smsMean = getComdataMean(comFreq, 'sms', 'smsUnique')\n",
    "smsMean = smsMean[cut:]\n",
    "x = np.arange(len(smsMean), dtype=np.double) \n",
    "errfunc = lambda p, x, y: np.sqrt(y**2 - (p[0]*x**p[1])**2)\n",
    "fit, _ = leastsq(errfunc, (85, -0.7), args=(x, smsMean))\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(x, smsMean, label='SMS data')\n",
    "ax.semilogy(x, fit[0]*x**fit[1], label=r'Fit: $%.2f x^{%.2f}$' % tuple(fit)) \n",
    "ax.semilogy(x, 330*x**-1.05, label=r\"My guess: $330.0 x^{-1.05}$\")\n",
    "ax.legend()\n",
    "ax.grid(which='minor') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the min and max dates… seems some users didn't set the time on their phones\n",
    " $a^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(df.timestamp.min(), df.timestamp.max() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print aliases for all usesr which have events before 2013 and after 2015, along with min and max dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for user in df.index.get_level_values('user').unique():\n",
    "    if df.loc[user].timestamp.min().year < 2013 or df.loc[user].timestamp.max().year > 2015:\n",
    "        print(user, df.loc[user].timestamp.min(), df.loc[user].timestamp.max(), sep=\"\\t\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a \"year\" column to the DataFrame, and plot a bar chart over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['year'] = df.timestamp.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there was some activity as early as in 2011. 1970 is proably relating to a reset phone counting for Unix time 0, and will be removed along with events which \"occured\" in 1980 and 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df.year.value_counts().sort_index().plot.bar()  \n",
    "ax.set_yscale('log')\n",
    "# ax.grid(which='minor')\n",
    "countsOnBarPlot(ax)\n",
    "ax.set_ylabel(\"Number of communication events\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "display(df.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the faulty rows, and ensure that the number of removed rows correspond to the number of rows matched in the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rowsBefore = df.shape[0] \n",
    "mask = (df.year < 2011) | (df.year > 2016)\n",
    "df = df[~mask]\n",
    "rowsBefore - df.shape[0] == mask.sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Timebin users activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ul = [\"u000%d\" % i for i in range(1, 10)] \n",
    "ul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfs = df.loc[ul]  \n",
    "dfs.index.get_level_values('user').unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs.resample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a matrix with a row for each user and a column for every hour, ranging from `df.timestamp.min()` to `df.timestamp.max()`.\n",
    "\n",
    "Next, make a function which calculates the index based on the datetime... maybe cast the `datetime` to an `int` and do some modulo magic like (`(timeInt - offset) % 3600`.\n",
    "\n",
    "If necessary, combine bins at nighttime afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:msth]",
   "language": "python",
   "name": "conda-env-msth-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
