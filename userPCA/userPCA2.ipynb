{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.algorithms.approximation as nxa\n",
    "import igraph as ig\n",
    "# http://stackoverflow.com/questions/35279733/what-could-cause-networkx-pygraphviz-to-work-fine-alone-but-not-together\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn import decomposition\n",
    "%matplotlib inline\n",
    "\n",
    "import missingno as msno\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "from speclib.loaders import (loadUserPhonenumberDict, getUserList, Useralias,\n",
    "                             loadUserParallel, dict2DataFrame, users2DataFrame)\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot, plotNeatoGraph\n",
    "from speclib.graph import networkx2igraph, igraph2networkx\n",
    "\n",
    "\n",
    "for k, v in {'font.size': 13.0,\n",
    "             'legend.fontsize': 13.0,\n",
    "             'axes.labelsize': 12.0,\n",
    "             'axes.titlesize': 15.0,\n",
    "             'figure.figsize': [16.0, 7.0],\n",
    "             'figure.dpi': 300,\n",
    "             'figure.titlesize': 'large',\n",
    "             'xtick.labelsize': 13.0,\n",
    "             'ytick.labelsize': 13.0}.items():\n",
    "    mpl.rcParams[k] = v\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Allan Leander Rostock Hansen\" -u -d -v -p numpy,bottleneck,pandas,matplotlib,sklearn,missingno,networkx,igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user SMS and call data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ua = Useralias()\n",
    "userSpec = [(user, ua[user], ('sms', 'call')) for user in getUserList()]\n",
    "userData = loadUserParallel(userSpec) \n",
    "df = users2DataFrame(userData, ua)\n",
    "del userData\n",
    "phonebook = loadUserPhonenumberDict(ua) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Make a subset of the data only containing communications contained within the Social Frabric project. Of this data, select a subset of the data containing the most active users, preferebly who communicate with each other… a clique percolation algorithm could be used for this, but that won't be the initial approach.\n",
    "\n",
    "A measure of the activity could simply be $$a = \\sum_{\\text{i}}\\frac{\\mathrm{user_{sms}}_i}{\\sum_i \\mathrm{user_{sms}}_i} + \\frac{\\mathrm{user_{call}}_i}{\\sum_i \\mathrm{user_{call}}_i}$$\n",
    "but this could yield a huge $a$ for a very active, yet weakly connected user, so a weighting with the number of contacted people shoud be introduced.\n",
    "\n",
    "Since a conversation using SMS regesters as several events for both users (usually), whereas a conversation carried out over a call registes as one event, a weighting should be introduced.\n",
    "The easy solution is to divide the adjacency matrices with the sum of all the entries, meaning that the sum of all the elements would both add up to one.\n",
    "Yet another approach would be to clean the SMS data in the following way:\n",
    "\n",
    "1. Investigate the distribution of time between a SMS and a reply to it.\n",
    "2. Use the distribution to determining a typical reply time.\n",
    "3. Remove entries in the SMS data which weren't replied to within some number, say 3, times the average reply time.\n",
    "\n",
    "Cleaning the SMS data as proposed above, should also prompt for a similar cleaning of the call data.\n",
    "An obvious way would be to remove unansvered calls, albeit the SMS dataset should also be checked for an \"answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the data munging\n",
    "\n",
    "Remove rows for which the contacted number is not present in `phonebook` (userhash to phonehash translation table).\n",
    "\n",
    "Also add a column which contaings the useralias (`u0001`, `u0345` and so on) for the contacted user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.number.apply(lambda num: num in phonebook)] \n",
    "df['contactedUser'] = df.number.apply(lambda x: phonebook[x]) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of unique contacts for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userUniqueCommCall = dict()   # dict for calls\n",
    "userUniqueCommSms = dict()  # dict for sms\n",
    "for user in df.index.get_level_values('user').unique():  # loop over users\n",
    "    try:  # 'call' data might be missing from some users\n",
    "        comSer = df.loc[user, 'call'].contactedUser\n",
    "        userUniqueCommCall[user] = comSer.unique().size\n",
    "    except KeyError:\n",
    "        userUniqueCommCall[user] = 0\n",
    "    try:  # 'sms' data might be missing from some users\n",
    "        comSer = df.loc[user, 'sms'].contactedUser\n",
    "        userUniqueCommSms[user] = comSer.unique().size\n",
    "    except KeyError:\n",
    "        userUniqueCommSms[user] = 0\n",
    "\n",
    "userUniqueComm = pd.DataFrame(pd.Series(userUniqueCommCall), columns=('call',))\n",
    "userUniqueComm['sms'] = pd.Series(userUniqueCommSms)\n",
    "userUniqueComm['total'] = userUniqueComm.sms + userUniqueComm.call\n",
    "del userUniqueCommCall\n",
    "del userUniqueCommSms\n",
    "\n",
    "userUniqueComm.sort(columns='total', inplace=True, ascending=False)\n",
    "display(userUniqueComm.head(), userUniqueComm.describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the findings, using two different plot styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2) \n",
    "userUniqueComm.plot.line(ax=ax0) \n",
    "userUniqueComm.drop('total', axis=1).plot.area(ax=ax1)\n",
    "fig.suptitle('Unique users conacted using Calls and SMS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A threshold of 20 unique contacts is used to select the most active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalCommunicationThreshold = 20\n",
    "chosenUsers = userUniqueComm.index[userUniqueComm.total > totalCommunicationThreshold]\n",
    "print(*chosenUsers, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute adjacency matrices\n",
    "Construct DataFrames for adjacency matrices/graphs for call and SMS data, where the index is the user initiating contact, and the columns is the users targeted by said contact.\n",
    "Selected users is limited to previously chosen active users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall = dict()  # dict for user calls\n",
    "adSms = dict()  # dict for user sms\n",
    "\n",
    "# for user in df.index.get_level_values('user').unique():\n",
    "for user in chosenUsers:\n",
    "    if 'call' in df.loc[user].index:  # user might not have 'call' data\n",
    "        cnt = df.loc[user, 'call'].contactedUser.value_counts()\n",
    "        adCall[user] = cnt.to_dict()\n",
    "    if 'sms' in df.loc[user].index:  # user might not have 'sms' data\n",
    "        cnt = df.loc[user, 'sms'].contactedUser.value_counts()\n",
    "        adSms[user] = cnt.to_dict() \n",
    "\n",
    "# Convert dicts to DataFrames and label the index and columns.\n",
    "adCall = pd.DataFrame(adCall)\n",
    "adSms = pd.DataFrame(adSms)\n",
    "adCall.columns.name = 'userRec'\n",
    "adSms.columns.name = 'userRec'\n",
    "adCall.index.name = 'userInit'\n",
    "adSms.index.name = 'userInit'\n",
    "\n",
    "# Drop contacted users which are'nt preset in the index (contact initating users) \n",
    "adCall.drop(list(set(adCall.columns) - set(adCall.index)), axis=1, inplace=True) \n",
    "adSms.drop(list(set(adSms.columns) - set(adSms.index)), axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the contributions for each dataset, such that $\\sum_{\\text{all entries}} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adCall /= np.nansum(adCall.values)\n",
    "# adSms /= np.nansum(adSms.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column where the activity level for each user is summed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall['activity'] = adCall.sum(axis=0, skipna=True)\n",
    "adSms['activity'] = adSms.sum(axis=0, skipna=True)\n",
    "\n",
    "# Sort the columns so that the 'activity' column is a the start of the Data Frame\n",
    "adCall.columns = adCall.columns.sort_values()\n",
    "adSms.columns = adSms.columns.sort_values() \n",
    "\n",
    "display(adCall.head(), adSms.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct graph objects\n",
    "A NetworkX graph is constructed from the DataFrame with the adjacency-matrix like data.\n",
    "The call and sms data is combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf = adCall + adSms\n",
    "adf.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dct = dict()  # keys is users which initiate contact (adf.index)\n",
    "# Remove newthe recently added activity column and make the activity measure binary (int8 for display putposes)\n",
    "adfNoActivity = (adf[adf.columns[adf.columns != 'activity']] > 0).astype(np.int8)\n",
    "display(adfNoActivity.head())\n",
    "\n",
    "for i, iUsr in enumerate(sorted(adf.index.unique())):  # Loop througth sorted user list\n",
    "    comSeries = adfNoActivity.loc[iUsr]  # Extract user communications\n",
    "    comSeries = comSeries.index[comSeries.astype(bool)]  # Filter the usernames (index) using the series masking data\n",
    "    dct[iUsr] = comSeries.tolist()    # Convert Pandas Series to a list\n",
    "g = nx.from_dict_of_lists(dct)  # costruct graph\n",
    "\n",
    "# Delete temporary variables\n",
    "del dct\n",
    "del adfNoActivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g, with_labels=True, node_color='lightblue', edge_color='lightgray', node_size=150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly some nodes aren't connected to the network – their contacts probably didn't meet the \"choose any users with 20 or more individual contacts\"-criterion.\n",
    "\n",
    "Nodes with no connections (that is, nodes with degree 0) are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for node, degree in dict(g.degree()).items():\n",
    "    if degree == 0:\n",
    "        g.remove_node(node) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify by plotting the network again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g, with_labels=True, node_color='lightblue', edge_color='lightgray', node_size=150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indeed looks like nodes with degree 0 are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply clique algorithms to find most active users\n",
    "\n",
    "<!--\n",
    "* Two algorithms is used.\n",
    "* I use the users returned from the biggest groups from both (14 users).\n",
    "* I also investigate the number overlap inbetween the two algorithms wrt. cliques and users.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify results from NetworkX using the iGraph library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ig = networkx2igraph(g) \n",
    "\n",
    "igraphCliques = ig.maximal_cliques() \n",
    "igraphCounter = Counter((len(el) for el in igraphCliques)) \n",
    "networkxCounter = Counter(len(el) for el in nx.algorithms.find_cliques(g))\n",
    "if networkxCounter == igraphCounter:\n",
    "    display(Markdown('Igraph and Networkx yields identical results.'))\n",
    "else:\n",
    "    display(Markdown('Igraph and Networkx yields different results!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clqdf = pd.DataFrame(nx.algorithms.find_cliques(g))\n",
    "clqdf['cliquesize'] = (~clqdf.isnull()).sum(axis=1)\n",
    "clqdf.sort(columns='cliquesize', ascending=False, inplace=True) \n",
    "clqdf.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "clqdf.cliquesize.value_counts().plot.bar(ax=ax, rot=0)\n",
    "ax.set_title(\"Clique size distribution\")\n",
    "looseAxesLimits(ax, [0.0, 0.0, 0.0, 0.1])\n",
    "countsOnBarPlot(ax)\n",
    "ax.set_xlabel('Clique size')\n",
    "ax.set_ylabel('Number of cliques') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove users which are not in a clique with size 6 or larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clqdf = clqdf[clqdf.cliquesize >= 6]\n",
    "clqdf.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make an array containing all the users in the selected clique(s) only once.\n",
    "* From that array, generate a new array which includes all the contacts of those users.\n",
    "* Extract a subgraph for those users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coreUsers = pd.Series(clqdf.drop('cliquesize', axis=1).values.flat).dropna().unique()  # Unique list of chosen users\n",
    "remoteUsers = [tuple(nx.neighbors(g, user)) for user in coreUsers]  # Chosen users neighbours\n",
    "remoteUsers = pd.Series(pd.DataFrame(remoteUsers).values.flat).dropna().unique()  # Make the array elements unique\n",
    "\n",
    "# Print the choice and the lengths of the array\n",
    "print('Core users in network ({} users):'.format(coreUsers.size))\n",
    "print(*coreUsers, sep='\\t', end='\\n'*2)\n",
    "print('Core users and their connections ({} users):'.format(remoteUsers.size))\n",
    "print(*remoteUsers, sep='\\t', end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the core users are included in the remote users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if set(coreUsers).issubset(set(remoteUsers)):\n",
    "    display(Markdown('All core users are contained in remote users.'))\n",
    "else:\n",
    "    display(Markdown('Remember to combine core users and remote users for subgraph extraction!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is expected, since the core users is a clique, and thus will be included among the links from the other users in the clique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the subgraph, and verify it by plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = g.subgraph(remoteUsers)  # The subset of the graph on which a PCA analysis should be performed on the users\n",
    "\n",
    "nx.draw(gs, with_labels=True, node_color='lightblue', edge_color='lightgray', node_size=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsDegdf = pd.DataFrame(gs.degree())\n",
    "gsDegdf.columns = ['user', 'degree']\n",
    "gsDegdf.set_index('user', inplace=True)\n",
    "gsDegdf.sort(columns='degree', ascending=False, inplace=True)\n",
    "display(gsDegdf.head())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(gsDegdf.degree,\n",
    "        range=(gsDegdf.degree.min(), gsDegdf.degree.max()+1),\n",
    "        bins=gsDegdf.degree.max()+1 - gsDegdf.degree.min())\n",
    "ax.minorticks_on() \n",
    "ax.grid(True, which='both')\n",
    "ax.set_xticks(range(0, gsDegdf.degree.max()+2, 5))\n",
    "ax.set_xbound(0, gsDegdf.degree.max()+2)\n",
    "ax.set_xlabel('Connectivity degree')\n",
    "ax.set_ylabel('Number of users')\n",
    "# countsOnBarPlot(ax)\n",
    "ax.set_title('Conectivity vs number of users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the PCA analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the adjacency matrix for the chosen network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsa = nx.adj_matrix(gs) \n",
    "fig, ax = plt.subplots() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mpl2]",
   "language": "python",
   "name": "conda-env-mpl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
