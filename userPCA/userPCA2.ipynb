{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.algorithms.approximation as nxa\n",
    "import igraph as ig\n",
    "# http://stackoverflow.com/questions/35279733/what-could-cause-networkx-pygraphviz-to-work-fine-alone-but-not-together\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn import decomposition\n",
    "%matplotlib inline\n",
    "\n",
    "for k, v in {'font.size': 13.0,\n",
    "             'legend.fontsize': 13.0,\n",
    "             'axes.labelsize': 12.0,\n",
    "             'axes.titlesize': 15.0,\n",
    "             'figure.figsize': [16.0, 7.0],\n",
    "             'figure.titlesize': 'large',\n",
    "             'xtick.labelsize': 13.0,\n",
    "             'ytick.labelsize': 13.0}.items():\n",
    "    mpl.rcParams[k] = v\n",
    "\n",
    "import missingno as msno\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from speclib.loaders import (loadUserPhonenumberDict, getUserList, Useralias,\n",
    "                             loadUserParallel, dict2DataFrame, users2DataFrame)\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot, plotNeatoGraph\n",
    "from speclib.graph import networkx2igraph, igraph2networkx\n",
    "\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Allan Leander Rostock Hansen\" -u -d -v -p numpy,bottleneck,pandas,matplotlib,sklearn,missingno,networkx,igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user SMS and call data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ua = Useralias()\n",
    "userSpec = [(user, ua[user], ('sms', 'call')) for user in getUserList()]\n",
    "userData = loadUserParallel(userSpec) \n",
    "df = users2DataFrame(userData, ua)\n",
    "del userData\n",
    "phonebook = loadUserPhonenumberDict(ua) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Make a subset of the data only containing communications contained within the Social Frabric project. Of this data, select a subset of the data containing the most active users, preferebly who communicate with each other… a clique percolation algorithm could be used for this, but that won't be the initial approach.\n",
    "\n",
    "A measure of the activity could simply be $$a = \\sum_{\\text{i}}\\frac{\\mathrm{user_{sms}}_i}{\\sum_i \\mathrm{user_{sms}}_i} + \\frac{\\mathrm{user_{call}}_i}{\\sum_i \\mathrm{user_{call}}_i}$$\n",
    "but this could yield a huge $a$ for a very active, yet weakly connected user, so a weighting with the number of contacted people shoud be introduced.\n",
    "\n",
    "Since a conversation using SMS regesters as several events for both users (usually), whereas a conversation carried out over a call registes as one event, a weighting should be introduced.\n",
    "The easy solution is to divide the adjacency matrices with the sum of all the entries, meaning that the sum of all the elements would both add up to one.\n",
    "Yet another approach would be to clean the SMS data in the following way:\n",
    "\n",
    "1. Investigate the distribution of time between a SMS and a reply to it.\n",
    "2. Use the distribution to determining a typical reply time.\n",
    "3. Remove entries in the SMS data which weren't replied to within some number, say 3, times the average reply time.\n",
    "\n",
    "Cleaning the SMS data as proposed above, should also prompt for a similar cleaning of the call data.\n",
    "An obvious way would be to remove unansvered calls, albeit the SMS dataset should also be checked for an \"answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the data munging\n",
    "\n",
    "Remove rows for which the contacted number is not present in `phonebook` (userhash to phonehash translation table).\n",
    "\n",
    "Also add a column which contaings the useralias (`u0001`, `u0345` and so on) for the contacted user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.number.apply(lambda num: num in phonebook)] \n",
    "df['contactedUser'] = df.number.apply(lambda x: phonebook[x]) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct DataFrames for call and SMS data, where the index is the user initiating contact, and the columns is the users targeted by said contact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userUniqueCommCall = dict()\n",
    "userUniqueCommSms = dict()\n",
    "for user in df.index.get_level_values('user').unique():\n",
    "    try:\n",
    "        comSer = df.loc[user, 'call'].contactedUser\n",
    "        userUniqueCommCall[user] = comSer.unique().size\n",
    "    except KeyError:\n",
    "        userUniqueCommCall[user] = 0\n",
    "    try:\n",
    "        comSer = df.loc[user, 'sms'].contactedUser\n",
    "        userUniqueCommSms[user] = comSer.unique().size\n",
    "    except KeyError:\n",
    "        userUniqueCommSms[user] = 0\n",
    "\n",
    "userUniqueComm = pd.DataFrame(pd.Series(userUniqueCommCall), columns=('call',))\n",
    "userUniqueComm['sms'] = pd.Series(userUniqueCommSms)\n",
    "userUniqueComm['total'] = userUniqueComm.sms + userUniqueComm.call\n",
    "del userUniqueCommCall\n",
    "del userUniqueCommSms\n",
    "\n",
    "userUniqueComm.sort(columns='total', inplace=True, ascending=False)\n",
    "display(userUniqueComm.head(), userUniqueComm.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2) \n",
    "userUniqueComm.plot.line(ax=ax0) \n",
    "userUniqueComm[['call', 'sms']].plot.area(ax=ax1)\n",
    "fig.suptitle('Unique users conacted using Calls and SMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userIndex = df.index.get_level_values('user').unique()\n",
    "adCall = dict()\n",
    "adSms = dict()\n",
    "\n",
    "for user in df.index.get_level_values('user').unique():\n",
    "    if 'call' in df.loc[user].index:\n",
    "        cnt = df.loc[user, 'call'].contactedUser.value_counts()\n",
    "        adCall[user] = cnt.to_dict()\n",
    "    if 'sms' in df.loc[user].index:\n",
    "        cnt = df.loc[user, 'sms'].contactedUser.value_counts()\n",
    "        adSms[user] = cnt.to_dict() \n",
    "\n",
    "# Convert dicts to DataFrames and label the index and columns.\n",
    "adCall = pd.DataFrame(adCall)\n",
    "adSms = pd.DataFrame(adSms)\n",
    "adCall.columns.name = 'userRec'\n",
    "adSms.columns.name = 'userRec'\n",
    "adCall.index.name = 'userInit'\n",
    "adSms.index.name = 'userInit'\n",
    "\n",
    "# Drop contacted users which are'nt preset in the index (contact initating users) \n",
    "adCall.drop(list(set(adCall.columns) - set(adCall.index)), axis=1, inplace=True) \n",
    "adSms.drop(list(set(adSms.columns) - set(adSms.index)), axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the contributions for each dataset, such that $\\sum_{\\text{all entries}} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adCall /= np.nansum(adCall.values)\n",
    "# adSms /= np.nansum(adSms.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column where the activity level for each user is summed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall['activity'] = adCall.sum(axis=0, skipna=True)\n",
    "adSms['activity'] = adSms.sum(axis=0, skipna=True)\n",
    "\n",
    "# Sort the columns so that the 'activity' column is a the start of the Data Frame\n",
    "adCall.columns = adCall.columns.sort_values()\n",
    "adSms.columns = adSms.columns.sort_values() \n",
    "\n",
    "display(adCall.head(), adSms.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with clique algorithms\n",
    "\n",
    "Finding users active in cliques.\n",
    "To do this, the data is loaded into networkx as a graph.\n",
    "\n",
    "* Two algorithms is used.\n",
    "* I use the users returned from the biggest groups from both (14 users).\n",
    "* I also investigate the number overlap inbetween the two algorithms wrt. cliques and users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf = adCall + adSms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dct = dict()  # keys is users which initiate contact (adf.index)\n",
    "# Remove newthe recently added activity column and make the activity measure binary (int8 for display putposes)\n",
    "adfNoActivity = (adf[adf.columns[adf.columns != 'activity']] > 0).astype(np.int8)\n",
    "display(adfNoActivity.head())\n",
    "\n",
    "for iUsr in sorted(adf.index.unique()):  # Loop througth sorted user list\n",
    "    comSeries = adfNoActivity.loc[iUsr]  # Extract user communications\n",
    "    dct[iUsr] = comSeries.tolist()   # Convert Pandas Series to a list\n",
    "g = nx.from_dict_of_lists(dct)  # costruct graph\n",
    "del dct  # Delete temporary variables\n",
    "del adfNoActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g, with_labels=True, node_color='lightblue', edge_color='lightgray', node_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ig = networkx2igraph(g) \n",
    "\n",
    "igraphCliques = ig.cliques() \n",
    "Counter((len(el) for el in igraphCliques)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count clique size for the two algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mclq = list(nx.algorithms.enumerate_all_cliques(g))\n",
    "mclq[::-1] \n",
    "cntMclq = Counter(len(el) for el in mclq)\n",
    "cntMclq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fclq = list(nx.algorithms.find_cliques(g))\n",
    "cntFclq = Counter(len(x) for x in fclq) \n",
    "cntFclq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fclqr = list(nx.algorithms.clique.find_cliques_recursive(g))\n",
    "cntFclqr = Counter(len(x) for x in fclqr)\n",
    "cntFclqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kclq = list(nx.algorithms.k_clique_communities(g, k=3))\n",
    "kclq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify graph by plotting it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "nx.draw(g, node_size=50, node_color='steelblue',\n",
    "        edge_color='lightgray', alpha=0.65, ax=ax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.isnull(adf[adf.columns[adf.columns != 'activity']]).sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(nx.algorithms.community.k_clique_communities(g, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mpl2]",
   "language": "python",
   "name": "conda-env-mpl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
