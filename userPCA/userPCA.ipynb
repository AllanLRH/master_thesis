{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "# http://stackoverflow.com/questions/35279733/what-could-cause-networkx-pygraphviz-to-work-fine-alone-but-not-together\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn import decomposition\n",
    "%matplotlib inline\n",
    "\n",
    "import missingno as msno\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from speclib.loaders import (loadUserPhonenumberDict, getUserList, Useralias,\n",
    "                             loadUserParallel, dict2DataFrame, users2DataFrame)\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot\n",
    "\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Allan Leander Rostock Hansen\" -u -d -v -p numpy,bottleneck,pandas,matplotlib,matplotlib.pyplot,sklearn,missingno,networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user SMS and call data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ua = Useralias()\n",
    "userSpec = [(user, ua[user], ('sms', 'call')) for user in getUserList()]\n",
    "userData = loadUserParallel(userSpec) \n",
    "df = users2DataFrame(userData, ua)\n",
    "del userData\n",
    "phonebook = loadUserPhonenumberDict(ua) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Make a subset of the data only containing communications contained within the Social Frabric project. Of this data, select a subset of the data containing the most active users, preferebly who communicate with each other… a clique percolation algorothm could be used for this, but that won't be the initial approach.\n",
    "\n",
    "A measure of the activity could simply be $$a = \\sum_{\\text{i}}\\frac{\\mathrm{user_{sms}}_i}{\\sum_i \\mathrm{user_{sms}}_i} + \\frac{\\mathrm{user_{call}}_i}{\\sum_i \\mathrm{user_{call}}_i}$$\n",
    "but this could yield a huge $a$ for a very active, yet weakly connected user, so a weighting with the number of contacted people shoud be introduced.\n",
    "\n",
    "Since a conversation using SMS regesters as several events for both users (usually), whereas a conversation carried out over a call registes as one event, a weighting should be introduced.\n",
    "The easy solution is to divide the adjacency matrices with the sum of all the entries, meaning that the sum of all the elements would both add up to one.\n",
    "Yet another approach would be to clean the SMS data in the following way:\n",
    "\n",
    "1. Investigate the distribution of time between a SMS and a reply to it.\n",
    "2. Use the distribution to determining a typical reply time.\n",
    "3. Remove entries in the SMS data which weren't replied to within some number, say 3, times the average reply time.\n",
    "\n",
    "Cleaning the SMS data as proposed above, should also prompt for a similar cleaning of the call data.\n",
    "An obvious way would be to remove unansvered calls, albeit the SMS dataset should also be checked for an \"answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the data munging\n",
    "\n",
    "Remove rows for which the contacted number is not present in `phonebook` (userhash to phonehash translation table).\n",
    "\n",
    "Also add a column which contaings the useralias (`u0001`, `u0345` and so on) for the contacted user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.number.apply(lambda num: num in phonebook)] \n",
    "df['contactedUser'] = df.number.apply(lambda x: phonebook[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a SMS and a call dataset.\n",
    "\n",
    "In these new DataFrames, make a list over all contacted users, and the amount of \"activity-time\" devoted to each contact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smsdf = df.loc[pd.IndexSlice[:, 'sms'], :] \n",
    "calldf = df.loc[pd.IndexSlice[:, 'call'], :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "userIndex = df.index.get_level_values('user').unique()\n",
    "adCall = pd.DataFrame(columns=userIndex, index=userIndex) \n",
    "adSms = pd.DataFrame(columns=userIndex, index=userIndex) \n",
    "\n",
    "for user in df.index.get_level_values('user').unique():\n",
    "    if 'call' in df.loc[user].index:\n",
    "        callCount = df.loc[user, 'call'].contactedUser.value_counts()\n",
    "        for u, c in zip(callCount.index, callCount.values):\n",
    "            adCall.loc[user, u] = c\n",
    "    if 'sms' in df.loc[user].index:\n",
    "        smsCount = df.loc[user, 'sms'].contactedUser.value_counts()\n",
    "        for u, c in zip(smsCount.index, smsCount.values):\n",
    "            adSms.loc[user, u] = c\n",
    "adCall /= adCall.sum().sum() \n",
    "adSms /= adSms.sum().sum() \n",
    "adCall.columns.name = 'userRec'\n",
    "adSms.columns.name = 'userRec'\n",
    "adCall.index.name = 'userInit'\n",
    "adSms.index.name = 'userInit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column where the activity level for each user is summed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall['activity'] = adCall.apply(lambda row: row.sum())\n",
    "adSms['activity'] = adSms.apply(lambda row: row.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kcom = nx.k_components(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kcom[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count clique size for the two algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mclq = list(nx.algorithms.enumerate_all_cliques(grp))\n",
    "mclq[::-1] \n",
    "cntMclq = Counter((len(el) for el in mclq))\n",
    "cntMclq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fclq = list(nx.algorithms.find_cliques(grp))\n",
    "cntFclq = Counter(len(x) for x in fclq) \n",
    "cntFclq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the algorithms into sets, compute the union and count how many times the usera are present in each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setMclq = {tuple(el) for el in mclq if len(el) == max(cntMclq)}\n",
    "setFclq = {tuple(el) for el in fclq if len(el) == max(cntFclq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clqCnt = Counter(el for tp in (setMclq.union(setFclq)) for el in tp)\n",
    "clqCnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intersection between the detected cliques are low (1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setMclq.intersection(setFclq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back the old measure (total activity)\n",
    "\n",
    "Find the n (=10) most active users. This should be replaced by a clique algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nMostActive = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getMostActive(activity):\n",
    "    ac = activity.values.astype(np.double)\n",
    "    ac[np.isnan(ac)] = 0\n",
    "    idx = np.argsort(ac)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf = adCall.iloc[getMostActive(adCall.activity)[-nMostActive:], :][::-1] \n",
    "sdf = adSms.iloc[getMostActive(adSms.activity)[-nMostActive:], :][::-1]\n",
    "display(cdf.head(), sdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 out of 10 users are present among the most active in both the SMS and call datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf.index.intersection(sdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try choosing users from the sum of SMS and call activity, thus choosing the same users in both datasets.\n",
    "Combine the two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = getMostActive(adSms.activity + adCall.activity)\n",
    "cdf = adCall.iloc[idx[-nMostActive:], :][::-1] \n",
    "sdf = adSms.iloc[idx[-nMostActive:], :][::-1]\n",
    "display(cdf, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the same users is used in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf.index.difference(sdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the DataFrames `sdf` and `cdf` under the name `adf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf = sdf + cdf\n",
    "adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting adjacency matrix... it's very sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use output from clique algorithms for user selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf = adCall.loc[clqCnt.keys()]\n",
    "sdf = adSms.loc[clqCnt.keys()]\n",
    "adf = cdf + sdf\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "adfData = adf.values.astype(np.double)[:, 1:]  # remove activity column\n",
    "pc = ax.pcolorfast(adfData, cmap=mpl.cm.rainbow)\n",
    "fig.colorbar(pc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing users which were not contacted, and plotting the new reduced adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "adfNoActivity = adf[adf.columns[1:]] \n",
    "mask = adfNoActivity.sum(axis=0).notnull()\n",
    "masked = adfNoActivity[mask[mask].index]\n",
    "toPlot = masked.values.astype(np.double)\n",
    "toPlot = np.ma.masked_array(toPlot, mask=np.isnan(toPlot))\n",
    "pc = ax.pcolor(toPlot, cmap=mpl.cm.plasma)\n",
    "fig.colorbar(pc) \n",
    "ax.set_yticks(np.arange(1, masked.shape[0]+1) - 0.5)\n",
    "ax.set_yticklabels(masked.index)\n",
    "ax.grid(False)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('Contacted users')\n",
    "ax.set_ylabel('Initiating users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The chosen users are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in adf.index:\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Construction the time series\n",
    "\n",
    "A time series for the users activity, binned for each quarter day are constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa = df.loc[list(adf.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfa.loc['u0250'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timebinning is done in the following way:\n",
    "\n",
    "<br>\n",
    "<font color=\"red\">Make sure to start the timedeltas from a sensible time, like midnight!</font>\n",
    "<br><br>\n",
    "\n",
    "1. Substract the minimum value for the timebin from all times, this starting comminication at time 0.\n",
    "2. Do integer division with 6*3600 (6 hours worth of seconds) to obtain timebin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa['timebin'] = (dfa.timeint - dfa.timeint.min())//(6*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa.loc['u0250'].timebin.value_counts().head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"red\"> Supervision by Joachim </font>\n",
    "\n",
    "1. Find a clique of about 10 people\n",
    "2. Make an adjacency matrix for those people which includes their contacts\n",
    "3. Cut network matrices into 6 hour intervals (or other interval)\n",
    "4. Turn interval-matrices into column-vectors\n",
    "5. \"Stack\" column vectors to a matrix\n",
    "6. Run PCA on matrix\n",
    "\n",
    "Also…\n",
    "* Make sure to understand, and be able to explain, clique/clustering algorithms and PCA algorithm\n",
    "* Make derivation of PCA algorithm\n",
    "* Brush up on index notation, because getting supervision by Joachim would otherwise be quite hard a times\n",
    "* <font color=\"red\"> *Send Joachim an email with results, possible derivations for PCA, and possible questions to show engagement and progress*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userIndex = dfa.index.get_level_values('user').unique()\n",
    "# dfh = pd.DataFrame(columns=(dfa.timebin.unique()))  # empty timebins not included\n",
    "dfh = pd.DataFrame(columns=(np.arange(dfa.timebin.min(), dfa.timebin.max())))  # empty timebins included\n",
    "for user in userIndex:\n",
    "    dfh.loc[user] = dfa.loc[user].timebin.value_counts()\n",
    "dfh.replace(np.NaN, 0.0, inplace=True)  # Replace NaN's with 0.0\n",
    "dfh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with `np.reshape` to ensure that I''m reshaping correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.arange(20).reshape((4, 5))\n",
    "display(arr, arr.reshape((arr.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember to normalize?\n",
    "* Sure about transpose?\n",
    "* Read up on PCA\n",
    "* Use decomposition.SparcePCA instead?\n",
    "* Talk to Joachim about PCA input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toPca = dfh.values.T.reshape((1, -1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA() \n",
    "pca.fit(dfh.values.T)\n",
    "print(pca.explained_variance_ratio_, pca.explained_variance_ratio_.sum(), sep='\\n\\nSum: ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(pca.components_[0])\n",
    "print(pca.components_[0].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfh.mean(axis=1).plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xax = np.arange(pca.explained_variance_ratio_.size) + 1\n",
    "ax.plot(xax, pca.explained_variance_ratio_, 'o--')\n",
    "ax.set_xticks(xax); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "pc = ax.matshow(pca.components_, cmap=mpl.cm.RdYlGn, vmin=-1, vmax=1)  # Spectral_r, bwr, RdYlBu_r, PiYG\n",
    "ax.grid(False)\n",
    "fig.colorbar(pc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play around with plotting using NetworkX-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adfDict = defaultdict(list)\n",
    "for init in adfNoActivity.index:\n",
    "    for recv in adfNoActivity.columns:\n",
    "        if not pd.isnull(adfNoActivity.loc[init, recv]):\n",
    "            # Don't use (userAlias, activity-fraction)-tuples as user indicators for now\n",
    "            # adfDict[init].append((recv, adfNoActivity.loc[init, recv]))\n",
    "            adfDict[init].append(recv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = nx.from_dict_of_lists(adfDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a simple plot of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(grp, node_size=70, node_color='steelblue', edge_color='lightblue') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dct = defaultdict(lambda: 0)\n",
    "for n0 in grp.nodes_iter():\n",
    "    for n1 in grp.nodes_iter():\n",
    "        if n0 != n1:\n",
    "            dct[n1] += nx.algorithms.node_connectivity(grp, n0, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostConnected = sorted(dct.items(), key=lambda x:x[1])[-10:]\n",
    "mostConnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostConnectedLabels = {el[0]: \"{} ({})\".format(*el) for el in mostConnected}\n",
    "mostConnectedLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw with labels for the 10 most connected users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in 1/np.sqrt(2**np.arange(1, 10)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(grp, k=k)\n",
    "    nx.draw_networkx_nodes(grp, pos, node_size=70, node_color='steelblue', ax=ax)\n",
    "    nx.draw_networkx_edges(grp, pos, edge_color='lightgray') \n",
    "    # nx.draw_networkx_labels(grp, pos, labels=toLabel, font_color='darkorange', font_size=15, font_weight='bold')\n",
    "    nx.draw_networkx_labels(grp, pos, labels=mostConnectedLabels,\n",
    "                            font_color='mediumaquamarine', font_size=15, font_weight='bold')\n",
    "    ax.set_axis_bgcolor('white')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(\"k = %.3f\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getColor(node):\n",
    "    \"\"\"Get colors from the vitidis color scheme\"\"\"\n",
    "    cols = np.array([mpl.colorbar.cm.viridis(i) for i in range(256)]) \n",
    "    valMax, valMin = max(dct.values()), min(dct.values())\n",
    "    nodeWeight = (dct[node] - valMin)/(valMax - valMin)\n",
    "    colIdx = 256*nodeWeight - 1\n",
    "    return cols[colIdx, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ccmap = [getColor(node) for node in grp.nodes_iter()]\n",
    "nx.draw(grp, pos, node_color=ccmap, node_size=80, ax=ax, alpha=0.55, edge_color='slategray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "pos = graphviz_layout(grp, prog='neato')\n",
    "nx.draw_networkx_nodes(grp, pos, node_size=70, node_color='steelblue', ax=ax)\n",
    "nx.draw_networkx_edges(grp, pos, edge_color='slategray') \n",
    "# nx.draw_networkx_labels(grp, pos, labels=toLabel, font_color='darkorange', font_size=15, font_weight='bold')\n",
    "nx.draw_networkx_labels(grp, pos, labels=mostConnectedLabels,\n",
    "                        font_color='mediumaquamarine', font_size=15, font_weight='bold')\n",
    "ax.set_axis_bgcolor('white')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kcom = nx.k_components(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kcom[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count clique size for the two algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mclq = list(nx.algorithms.enumerate_all_cliques(grp))\n",
    "mclq[::-1] \n",
    "cntMclq = Counter((len(el) for el in mclq))\n",
    "cntMclq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fclq = list(nx.algorithms.find_cliques(grp))\n",
    "cntFclq = Counter(len(x) for x in fclq) \n",
    "cntFclq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the algorithms into sets, compute the union and count how many times the usera are present in each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setMclq = {tuple(el) for el in mclq if len(el) == max(cntMclq)}\n",
    "setFclq = {tuple(el) for el in fclq if len(el) == max(cntFclq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(el for tp in (setMclq.union(setFclq)) for el in tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intersection between the detected cliques are low (1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setMclq.intersection(setFclq) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mpl2]",
   "language": "python",
   "name": "conda-env-mpl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
