{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "# http://stackoverflow.com/questions/35279733/what-could-cause-networkx-pygraphviz-to-work-fine-alone-but-not-together\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn import decomposition\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "\n",
    "import missingno as msno\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from speclib.loaders import (loadUserPhonenumberDict, getUserList, Useralias,\n",
    "                             loadUserParallel, dict2DataFrame, users2DataFrame)\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user SMS and call data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%watermark -a \"Allan Leander Rostock Hansen\" -u -d -v -p numpy,bottleneck,pandas,matplotlib,matplotlib.pyplot,sklearn,missingno,networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ua = Useralias()\n",
    "userSpec = [(user, ua[user], ('sms', 'call')) for user in getUserList()]\n",
    "userData = loadUserParallel(userSpec) \n",
    "df = users2DataFrame(userData, ua)\n",
    "del userData\n",
    "phonebook = loadUserPhonenumberDict(ua) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Make a subset of the data only containing communications contained within the Social Frabric project. Of this data, select a subset of the data containing the most active users, preferebly who communicate with each other… a clique percolation algorothm could be used for this, but that won't be the initial approach.\n",
    "\n",
    "A measure of the activity could simply be $$a = \\sum_{\\text{i}}\\frac{\\mathrm{user_{sms}}_i}{\\sum_i \\mathrm{user_{sms}}_i} + \\frac{\\mathrm{user_{call}}_i}{\\sum_i \\mathrm{user_{call}}_i}$$\n",
    "but this could yield a huge $a$ for a very active, yet weakly connected user, so a weighting with the number of contacted people shoud be introduced.\n",
    "\n",
    "Since a conversation using SMS regesters as several events for both users (usually), whereas a conversation carried out over a call registes as one event, a weighting should be introduced.\n",
    "The easy solution is to divide the adjacency matrices with the sum of all the entries, meaning that the sum of all the elements would both add up to one.\n",
    "Yet another approach would be to clean the SMS data in the following way:\n",
    "\n",
    "1. Investigate the distribution of time between a SMS and a reply to it.\n",
    "2. Use the distribution to determining a typical reply time.\n",
    "3. Remove entries in the SMS data which weren't replied to within some number, say 3, times the average reply time.\n",
    "\n",
    "Cleaning the SMS data as proposed above, should also prompt for a similar cleaning of the call data.\n",
    "An obvious way would be to remove unansvered calls, albeit the SMS dataset should also be checked for an \"answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the data munging\n",
    "\n",
    "Remove rows for which the contacted number is not present i `phonebook` (userhash to phonehash translation table).\n",
    "\n",
    "Also add a column which contaings the useralias (`u0001`, `u0345` and so on) for the contacted user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.number.apply(lambda num: num in phonebook)] \n",
    "df['contactedUser'] = df.number.apply(lambda x: phonebook[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smsdf = df.loc[pd.IndexSlice[:, 'sms'], :] \n",
    "calldf = df.loc[pd.IndexSlice[:, 'call'], :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "userIndex = df.index.get_level_values('user').unique()\n",
    "adCall = pd.DataFrame(columns=userIndex, index=userIndex) \n",
    "adSms = pd.DataFrame(columns=userIndex, index=userIndex) \n",
    "\n",
    "for user in df.index.get_level_values('user').unique():\n",
    "    if 'call' in df.loc[user].index:\n",
    "        callCount = df.loc[user, 'call'].contactedUser.value_counts()\n",
    "        for u, c in zip(callCount.index, callCount.values):\n",
    "            adCall.loc[user, u] = c\n",
    "    if 'sms' in df.loc[user].index:\n",
    "        smsCount = df.loc[user, 'sms'].contactedUser.value_counts()\n",
    "        for u, c in zip(smsCount.index, smsCount.values):\n",
    "            adSms.loc[user, u] = c\n",
    "adCall /= adCall.sum().sum() \n",
    "adSms /= adSms.sum().sum() \n",
    "adCall.columns.name = 'userRec'\n",
    "adSms.columns.name = 'userRec'\n",
    "adCall.index.name = 'userInit'\n",
    "adSms.index.name = 'userInit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall['activity'] = adCall.apply(lambda row: row.sum())\n",
    "adSms['activity'] = adSms.apply(lambda row: row.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nMostActive = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getMostActive(activity):\n",
    "    ac = activity.values.astype(np.double)\n",
    "    ac[np.isnan(ac)] = 0\n",
    "    idx = np.argsort(ac)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf = adCall.iloc[getMostActive(adCall.activity)[-nMostActive:], :][::-1] \n",
    "sdf = adSms.iloc[getMostActive(adSms.activity)[-nMostActive:], :][::-1]\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 out of 10 users are present among the most active in both the SMS and call datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf.index.intersection(sdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try choosing users from the sum of SMS and call activity, thus choosing the same users in both datasets.\n",
    "Combine the two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = getMostActive(adSms.activity + adCall.activity)\n",
    "cdf = adCall.iloc[idx[-nMostActive:], :][::-1] \n",
    "sdf = adSms.iloc[idx[-nMostActive:], :][::-1]\n",
    "display(cdf, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the same users is used in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf.index.difference(sdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf = sdf + cdf\n",
    "adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting adjacency matrix... it's very sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "adfData = adf.values.astype(np.double)[:, 1:]  # remove activity column\n",
    "pc = ax.pcolorfast(adfData, cmap=mpl.cm.rainbow)\n",
    "fig.colorbar(pc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing users which were not contacted, and plotting the new reduced adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "adfNoActivity = adf[adf.columns[1:]] \n",
    "mask = adfNoActivity.sum(axis=0).notnull()\n",
    "masked = adfNoActivity[mask[mask].index]\n",
    "toPlot = masked.values.astype(np.double)\n",
    "toPlot = np.ma.masked_array(toPlot, mask=np.isnan(toPlot))\n",
    "pc = ax.pcolor(toPlot, cmap=mpl.cm.plasma)\n",
    "fig.colorbar(pc) \n",
    "ax.set_yticks(np.arange(1, masked.shape[0]+1) - 0.5)\n",
    "ax.set_yticklabels(masked.index)\n",
    "ax.grid(False)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('Contacted users')\n",
    "ax.set_ylabel('Initiating users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The chosen users are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in adf.index:\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Construction the time series\n",
    "\n",
    "A time series for the users activity, binned for each quarter day are constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa = df.loc[list(adf.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfa.loc['u0250'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timebinning is done in the following way:\n",
    "\n",
    "1. Substract the minimum value for the timebin from all times, this starting comminication at time 0.\n",
    "2. Do integer division with 6*3600 (6 hours worth of seconds) to obtain timebin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa['timebin'] = (dfa.timeint - dfa.timeint.min())//(6*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa.loc['u0250'].timebin.value_counts().head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"red\"> Supervision by Joachim </font>\n",
    "\n",
    "1. Find a clique of about 10 people\n",
    "2. Make an adjacency matrix for those people which includes their contacts\n",
    "3. Cut network matrices into 6 hour intervals (or other interval)\n",
    "4. Turn interval-matrices into column-vectors\n",
    "5. \"Stack\" column vectors to a matrix\n",
    "6. Run PCA on matrix\n",
    "\n",
    "Also…\n",
    "* Make sure to understand, and be able to explain, clique/clustering algorithms and PCA algorithm\n",
    "* Make derivation of PCA algorithm\n",
    "* Brush up on index notation, because getting supervision by Joachim would otherwise be quite hard a times\n",
    "* <font color=\"red\"> *Send Joachim an email with results, possible derivations for PCA, and possible questions to show engagement and progress*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userIndex = dfa.index.get_level_values('user').unique()\n",
    "# dfh = pd.DataFrame(columns=(dfa.timebin.unique()))  # empty timebins not included\n",
    "dfh = pd.DataFrame(columns=(np.arange(dfa.timebin.min(), dfa.timebin.max())))  # empty timebins included\n",
    "for user in userIndex:\n",
    "    dfh.loc[user] = dfa.loc[user].timebin.value_counts()\n",
    "dfh.replace(np.NaN, 0.0, inplace=True)  # Replace NaN's with 0.0\n",
    "dfh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with `np.reshape` to ensure that I''m reshaping correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.arange(20).reshape((4, 5))\n",
    "display(arr, arr.reshape((arr.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember to normalize?\n",
    "* Sure about transpose?\n",
    "* Read up on PCA\n",
    "* Use decomposition.SparcePCA instead?\n",
    "* Talk to Joachim about PCA input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toPca = dfh.values.T.reshape((1, -1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA() \n",
    "pca.fit(dfh.values.T)\n",
    "print(pca.explained_variance_ratio_, pca.explained_variance_ratio_.sum(), sep='\\n\\nSum: ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(pca.components_[0])\n",
    "print(pca.components_[0].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfh.mean(axis=1).plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xax = np.arange(pca.explained_variance_ratio_.size) + 1\n",
    "ax.plot(xax, pca.explained_variance_ratio_, 'o--')\n",
    "ax.set_xticks(xax); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "pc = ax.matshow(pca.components_, cmap=mpl.cm.RdYlGn, vmin=-1, vmax=1)  # Spectral_r, bwr, RdYlBu_r, PiYG\n",
    "ax.grid(False)\n",
    "fig.colorbar(pc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play around with plotting using NetworkX-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adfDict = defaultdict(list)\n",
    "for init in adfNoActivity.index:\n",
    "    for recv in adfNoActivity.columns:\n",
    "        if not pd.isnull(adfNoActivity.loc[init, recv]):\n",
    "            adfDict[init].append((recv, adfNoActivity.loc[init, recv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = nx.from_dict_of_lists(adfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(grp, node_size=70, node_color='steelblue', edge_color='lightblue') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc = (nx.algorithms.all_pairs_node_connectivity(grp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dct = defaultdict(lambda: 0)\n",
    "for n0 in grp.nodes_iter():\n",
    "    for n1 in grp.nodes_iter():\n",
    "        if n0 != n1:\n",
    "            dct[n1] += nx.algorithms.node_connectivity(grp, n0, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostConnected = sorted(dct.items(), key=lambda x:x[1])[-10:]\n",
    "mostConnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostConnectedLabels = {nd[0]: nd[0][0] for nd in mostConnected}\n",
    "mostConnectedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw = [(nd[0], float(nd[1])) for nd in grp.nodes_iter()]\n",
    "fw.sort(key=lambda x: x[1])\n",
    "toLabel = {nd: nd[0] for nd in fw[-10:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pos = nx.spring_layout(grp)\n",
    "nx.draw_networkx_nodes(grp, pos, node_size=70, node_color='steelblue', ax=ax)\n",
    "nx.draw_networkx_edges(grp, pos, edge_color='slategray') \n",
    "nx.draw_networkx_labels(grp, pos, labels=toLabel, font_color='darkorange', font_size=15, font_weight='bold')\n",
    "nx.draw_networkx_labels(grp, pos, labels=mostConnectedLabels,\n",
    "                        font_color='mediumaquamarine', font_size=15, font_weight='bold')\n",
    "ax.set_axis_bgcolor('white')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getColor(node):\n",
    "    cols = np.array([mpl.colorbar.cm.viridis(i) for i in range(256)]) \n",
    "    nodeWeights = [float(nd[1]) for nd in grp.nodes_iter()]\n",
    "    colIdx = float(node[1]) * 255/(max(nodeWeights) - min(nodeWeights))\n",
    "    return cols[colIdx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ccmap = [getColor(node) for node in grp.nodes_iter()]\n",
    "nx.draw(grp, pos, node_color=ccmap, node_size=80, ax=ax, alpha=0.55, edge_color='slategray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "pos = graphviz_layout(grp, prog='neato')\n",
    "nx.draw_networkx_nodes(grp, pos, node_size=70, node_color='steelblue', ax=ax)\n",
    "nx.draw_networkx_edges(grp, pos, edge_color='slategray') \n",
    "nx.draw_networkx_labels(grp, pos, labels=toLabel, font_color='darkorange', font_size=15, font_weight='bold')\n",
    "nx.draw_networkx_labels(grp, pos, labels=mostConnectedLabels,\n",
    "                        font_color='mediumaquamarine', font_size=15, font_weight='bold')\n",
    "ax.set_axis_bgcolor('white')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mpl2]",
   "language": "python",
   "name": "conda-env-mpl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
