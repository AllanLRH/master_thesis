{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition\n",
    "%matplotlib inline\n",
    "\n",
    "import missingno as msno\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from speclib.loaders import (loadUserPhonenumberDict, getUserList, Useralias,\n",
    "                             loadUserParallel, dict2DataFrame, users2DataFrame)\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user SMS and call data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ua = Useralias()\n",
    "userSpec = [(user, ua[user], ('sms', 'call')) for user in getUserList()]\n",
    "userData = loadUserParallel(userSpec) \n",
    "df = users2DataFrame(userData, ua)\n",
    "del userData\n",
    "phonebook = loadUserPhonenumberDict(ua) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Make a subset of the data only containing communications contained within the Social Frabric project. Of this data, select a subset of the data containing the most active users, preferebly who communicate with each other… a clique percolation algorothm could be used for this, but that won't be the initial approach.\n",
    "\n",
    "A measure of the activity could simply be $$a = \\sum_{\\text{i}}\\frac{\\mathrm{user_{sms}}_i}{\\sum_i \\mathrm{user_{sms}}_i} + \\frac{\\mathrm{user_{call}}_i}{\\sum_i \\mathrm{user_{call}}_i}$$\n",
    "but this could yield a huge $a$ for a very active, yet weakly connected user, so a weighting with the number of contacted people shoud be introduced.\n",
    "\n",
    "Since a conversation using SMS regesters as several events for both users (usually), whereas a conversation carried out over a call registes as one event, a weighting should be introduced.\n",
    "The easy solution is to divide the adjacency matrices with the sum of all the entries, meaning that the sum of all the elements would both add up to one.\n",
    "Yet another approach would be to clean the SMS data in the following way:\n",
    "\n",
    "1. Investigate the distribution of time between a SMS and a reply to it.\n",
    "2. Use the distribution to determining a typical reply time.\n",
    "3. Remove entries in the SMS data which weren't replied to within some number, say 3, times the average reply time.\n",
    "\n",
    "Cleaning the SMS data as proposed above, should also prompt for a similar cleaning of the call data.\n",
    "An obvious way would be to remove unansvered calls, albeit the SMS dataset should also be checked for an \"answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the data munging\n",
    "\n",
    "Remove rows for which the contacted number is not present i `phonebook` (userhash to phonehash translation table).\n",
    "\n",
    "Also add a column which contaings the useralias (`u0001`, `u0345` and so on) for the contacted user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.number.apply(lambda num: num in phonebook)] \n",
    "df['contactedUser'] = df.number.apply(lambda x: phonebook[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smsdf = df.loc[pd.IndexSlice[:, 'sms'], :] \n",
    "calldf = df.loc[pd.IndexSlice[:, 'call'], :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "userIndex = df.index.get_level_values('user').unique()\n",
    "adCall = pd.DataFrame(columns=userIndex, index=userIndex) \n",
    "adSms = pd.DataFrame(columns=userIndex, index=userIndex) \n",
    "\n",
    "for user in df.index.get_level_values('user').unique():\n",
    "    if 'call' in df.loc[user].index:\n",
    "        callCount = df.loc[user, 'call'].contactedUser.value_counts()\n",
    "        for u, c in zip(callCount.index, callCount.values):\n",
    "            adCall.loc[user, u] = c\n",
    "    if 'sms' in df.loc[user].index:\n",
    "        smsCount = df.loc[user, 'sms'].contactedUser.value_counts()\n",
    "        for u, c in zip(smsCount.index, smsCount.values):\n",
    "            adSms.loc[user, u] = c\n",
    "adCall /= adCall.sum().sum() \n",
    "adSms /= adSms.sum().sum() \n",
    "adCall.columns.name = 'userRec'\n",
    "adSms.columns.name = 'userRec'\n",
    "adCall.index.name = 'userInit'\n",
    "adSms.index.name = 'userInit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall['activity'] = adCall.apply(lambda row: row.sum())\n",
    "adSms['activity'] = adSms.apply(lambda row: row.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adCall.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nMostActive = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getMostActive(activity):\n",
    "    ac = activity.values.astype(np.double)\n",
    "    ac[np.isnan(ac)] = 0\n",
    "    idx = np.argsort(ac)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf = adCall.iloc[getMostActive(adCall.activity)[-nMostActive:], :][::-1] \n",
    "sdf = adSms.iloc[getMostActive(adSms.activity)[-nMostActive:], :][::-1]\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 out of 10 users are present among the most active in both the SMS and call datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf.index.intersection(sdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try choosing users from the sum of SMS and call activity, thus choosing the same users in both datasets.\n",
    "Combine the two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = getMostActive(adSms.activity + adCall.activity)\n",
    "cdf = adCall.iloc[idx[-nMostActive:], :][::-1] \n",
    "sdf = adSms.iloc[idx[-nMostActive:], :][::-1]\n",
    "display(cdf, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the same users is used in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf.index.difference(sdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf = sdf + cdf\n",
    "adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting adjacency matrix... it's very sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "adfData = adf.values.astype(np.double)[:, 1:]  # remove activity column\n",
    "pc = ax.pcolorfast(adfData, cmap=mpl.cm.rainbow)\n",
    "fig.colorbar(pc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing users which were not contacted, and plotting the new reduced adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "adfNoActivity = adf[adf.columns[1:]] \n",
    "mask = adfNoActivity.sum(axis=0).notnull()\n",
    "masked = adfNoActivity[mask[mask].index]\n",
    "toPlot = masked.values.astype(np.double)\n",
    "toPlot = np.ma.masked_array(toPlot, mask=np.isnan(toPlot))\n",
    "pc = ax.pcolor(toPlot, cmap=mpl.cm.plasma)\n",
    "fig.colorbar(pc) \n",
    "ax.set_yticks(np.arange(1, masked.shape[0]+1) - 0.5)\n",
    "ax.set_yticklabels(masked.index)\n",
    "ax.grid(False)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('Contacted users')\n",
    "ax.set_ylabel('Initiating users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The chosen users are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in adf.index:\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Construction the time series\n",
    "\n",
    "A time series for the users activity, binned for each quarter day are constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa = df.loc[list(adf.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfa.loc['u0250'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timebinning is done in the following way:\n",
    "\n",
    "1. Substract the minimum value for the timebin from all times, this starting comminication at time 0.\n",
    "2. Do integer division with 6*3600 (6 hours worth of seconds) to obtain timebin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa['timebin'] = (dfa.timeint - dfa.timeint.min())//(6*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa.loc['u0250'].timebin.value_counts().head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userIndex = dfa.index.get_level_values('user').unique()\n",
    "# dfh = pd.DataFrame(columns=(dfa.timebin.unique()))  # empty timebins not included\n",
    "dfh = pd.DataFrame(columns=(np.arange(dfa.timebin.min(), dfa.timebin.max())))  # empty timebins included\n",
    "for user in userIndex:\n",
    "    dfh.loc[user] = dfa.loc[user].timebin.value_counts()\n",
    "dfh.replace(np.NaN, 0.0, inplace=True)  # Replace NaN's with 0.0\n",
    "dfh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with `np.reshape` to ensure that I''m reshaping correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.arange(20).reshape((4, 5))\n",
    "display(arr, arr.reshape((arr.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember to normalize?\n",
    "* Sure about transpose?\n",
    "* Read up on PCA\n",
    "* Use decomposition.SparcePCA instead?\n",
    "* Talk to Joachim about PCA input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toPca = dfh.values.T.reshape((1, dfh.values.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(dfh.values.T)\n",
    "print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mpl2]",
   "language": "python",
   "name": "conda-env-mpl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
