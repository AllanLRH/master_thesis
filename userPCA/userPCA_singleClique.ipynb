{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import itertools\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "import networkx as nx\n",
    "# import networkx.algorithms.approximation as nxa\n",
    "import igraph as ig\n",
    "# # http://stackoverflow.com/questions/35279733/what-could-cause-networkx-pygraphviz-to-work-fine-alone-but-not-together\n",
    "# from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".95\"})\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from IPython.display import display as disp\n",
    "\n",
    "from speclib.loaders import (loadUserPhonenumberDict, getUserList, Useralias,\n",
    "                             loadUserParallel, dict2DataFrame, users2DataFrame)\n",
    "from speclib.plotting import looseAxesLimits, barSBS, countsOnBarPlot, plotNeatoGraph, nxQuickDraw, barFractionPlot\n",
    "from speclib.graph import networkx2igraph, igraph2networkx, userDF2nxGraph, userDF2activityDataframe\n",
    "from speclib.misc import nanEqual, timedelta2unit, standardizeData, pcaFit\n",
    "from speclib.userActivityFunctions import mutualContact, userDf2timebinDf, userDf2timebinAdjMat, userDf2CliqueDf\n",
    "\n",
    "for k, v in {'font.size': 13.0,\n",
    "             'legend.fontsize': 13.0,\n",
    "             'axes.labelsize': 12.0,\n",
    "             'axes.titlesize': 15.0,\n",
    "             'figure.figsize': [16.0, 7.0],\n",
    "             'figure.dpi': 200,\n",
    "             'figure.titlesize': 'large',\n",
    "             'xtick.labelsize': 13.0,\n",
    "             'ytick.labelsize': 13.0}.items():\n",
    "    mpl.rcParams[k] = v\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Allan Leander Rostock Hansen\" -u -d -v -p numpy,bottleneck,pandas,matplotlib,sklearn,missingno\n",
    "%watermark  -p networkx,igraph,seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('phone_df.h5'):\n",
    "    df = pd.io.pytables.read_hdf('phone_df.h5', 'df')\n",
    "    import pickle\n",
    "    with open('useralias.pk', 'br') as fid:\n",
    "        ua = pickle.load(fid)\n",
    "else:\n",
    "    ua = Useralias()\n",
    "    userSpec = [(user, ua[user], ('sms', 'call')) for user in getUserList()]\n",
    "    userData = loadUserParallel(userSpec) \n",
    "    df = users2DataFrame(userData, ua)\n",
    "    del userData\n",
    "phonebook = loadUserPhonenumberDict(ua) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove call to users not in phonebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.number.isin(phonebook)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add _contactedUser_ column and remove the _number_ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['contactedUser'] = df.number.apply(lambda x: phonebook[x]) \n",
    "df = df.drop('number', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for obvious outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df.timestamp.dt.year.value_counts().sort_index(ascending=True).plot.bar() \n",
    "countsOnBarPlot(ax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove data preceding 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.timestamp.dt.year >= 2013] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove entries with users contacting themself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = df.reset_index()\n",
    "tmp = tmp[(tmp.user != tmp.contactedUser)]\n",
    "df = tmp.set_index(['user', 'comtype'], drop=False)\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn data into a Networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = userDF2nxGraph(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the graph contains the correct number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(list(g.nodes())) == len(set(df.index.get_level_values('user').tolist() + df.contactedUser.tolist())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cnt = Counter(el[1] for el in g.degree())\n",
    "x, y = list(zip(*((i, cnt[i]) for i in range(max(cnt)+1))))\n",
    "ax.bar(x, y)\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Counts')\n",
    "countsOnBarPlot(ax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community detection\n",
    "\n",
    "Find communities consisting of 5-cliques with a 4 degree connection between the cliques.\n",
    "<font color=\"red\">Check up on this!</font>\n",
    "\n",
    "[From Documentation](http://networkx.readthedocs.io/en/latest/reference/generated/networkx.algorithms.community.kclique.k_clique_communities.html#networkx.algorithms.community.kclique.k_clique_communities):\n",
    "\n",
    "> Find _k_-clique communities in graph using the percolation method.\n",
    "> \n",
    "> A _k_-clique community is the union of all cliques of size _k_ that can be reached through adjacent (sharing _k_-1 nodes) _k_-cliques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kcDf = pd.DataFrame(sorted(nx.algorithms.community.k_clique_communities(g, 5), key=lambda x: len(x), reverse=True))\n",
    "kcDf.columns.name = 'users'\n",
    "kcDf.index.name = 'communityNumber'\n",
    "disp(kcDf.head())\n",
    "\n",
    "gsc = g.subgraph(kcDf.iloc[0])\n",
    "nxQuickDraw(gsc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clique detection\n",
    "\n",
    "Could be used for analysis of a larger network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliqueDf = pd.DataFrame(nx.clique.find_cliques_recursive(g))\n",
    "\n",
    "cliqueDf['cliqueSize'] = cliqueDf.count(axis=1)\n",
    "cliqueDf = cliqueDf.sort_values('cliqueSize', ascending=False)\n",
    "\n",
    "ax = cliqueDf.cliqueSize.value_counts().sort_index().plot.bar(rot=0) \n",
    "ax.set_xlabel('Clique size') \n",
    "ax.set_ylabel('Counts') \n",
    "countsOnBarPlot(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a clique with 5 users and make a subgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenUserLst = cliqueDf[cliqueDf.cliqueSize == 5].drop('cliqueSize', axis=1).iloc[1].dropna().tolist()\n",
    "print(\"Chosen users:\", *chosenUserLst, sep='\\n') \n",
    "gs = g.subgraph(chosenUserLst)\n",
    "nxQuickDraw(gs, plotSettings={'with_labels': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create timebinning for chosen users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction of users contribution to communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userDF2activityDataframe(df.loc[chosenUserLst]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(ax, userOrder) = barFractionPlot(userDF2activityDataframe(df.loc[chosenUserLst]).sum(axis=1)) \n",
    "ax.set_title('Communication with everybody')\n",
    "cliqueSubActDf = userDF2activityDataframe(userDf2CliqueDf(df, chosenUserLst)).sum(axis=1)\n",
    "(ax, userOrder) = barFractionPlot(cliqueSubActDf, userOrder=userOrder) \n",
    "ax.set_title('Communication within the clique') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliqueSubDf = userDf2CliqueDf(df, chosenUserLst)\n",
    "toPcaRaw = userDf2timebinAdjMat(cliqueSubDf, 6, chosenUserLst)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pc = ax.pcolorfast(toPcaRaw) \n",
    "fig.colorbar(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = pcaFit(toPcaRaw)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(pca.explained_variance_ratio_)\n",
    "ax.set_xlabel('Eigenvalue #') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliqueDf = pd.DataFrame(nx.clique.find_cliques_recursive(g))\n",
    "cliqueDf['cliqueSize'] = cliqueDf.count(axis=1)\n",
    "cliqueDf = cliqueDf.sort_values('cliqueSize', ascending=False)\n",
    "\n",
    "binsCalendarDay = 6\n",
    "cliquePcaDct = dict()\n",
    "cliqueSizeLst = [x for x in cliqueDf.cliqueSize.unique() if x > 2]\n",
    "for cs in cliqueSizeLst:\n",
    "    cliquePcaDct[cs] = list()\n",
    "    for clique in cliqueDf[cliqueDf.cliqueSize == cs].iloc[:, :cs].values:\n",
    "        clique = clique.tolist()\n",
    "        cliqueSubDf = userDf2CliqueDf(df, clique)\n",
    "        toPcaRaw = userDf2timebinAdjMat(cliqueSubDf, binsCalendarDay, clique)\n",
    "        pca = pcaFit(toPcaRaw)\n",
    "        cliquePcaDct[cs].append(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import palettable\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "colors = palettable.colorbrewer.qualitative.Dark2_5_r.mpl_colors\n",
    "for i, cs in enumerate(sorted(cliquePcaDct.keys())):\n",
    "    csDf = pd.DataFrame(cliquePcaDct[cs])\n",
    "    upper, mean, median, lower, std = csDf.max(axis=0), csDf.mean(axis=0), csDf.median(axis=0), csDf.min(axis=0), csDf.std(axis=0)\n",
    "    ax.plot(mean+i, '-o', color=colors[i], label='clique size %d' % cs)\n",
    "    # ax.errorbar(range(len(mean)), mean+i, uplims=upper, lolims=lower, color=colors[i])\n",
    "    ax.fill_between(range(len(mean)), upper+i, lower+i, color=colors[i], alpha=0.4)\n",
    "ax.legend(loc='lower right', fancybox=True, framealpha=0.8)\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('clique_pca_evr_dump.pickle', 'wb') as fid:\n",
    "    pickle.dump(cliquePcaDct, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def getPcaExplainedVarianceRatio(cliqueSubDf, chosenUserLst, binsCalendarDay):\n",
    "#         toPcaRaw = userDf2timebinAdjMat(cliqueSubDf, binsCalendarDay, chosenUserLst)\n",
    "#         pca = pcaFit(toPcaRaw)\n",
    "#         return (len(chosenUserLst), pca.explained_variance_ratio_.copy()) \n",
    "# \n",
    "# def getPcaExplainedVarianceRatio_handler(x):\n",
    "#     return getPcaExplainedVarianceRatio(*x) \n",
    "# \n",
    "# def foo(inp):\n",
    "#     toPca, cs = inp\n",
    "#     pca = decomposition.PCA()\n",
    "#     pca.fit(standardizeData(toPca))\n",
    "#     return (cs, pca.explained_variance_ratio_)\n",
    "# \n",
    "# try:\n",
    "#     pool = multiprocessing.Pool(processes=2)\n",
    "# \n",
    "#     callArgList = list()\n",
    "#     binsCalendarDay = 6\n",
    "#     cliqueSizeLst = [x for x in cliqueDf.cliqueSize.unique() if x > 6]\n",
    "#     for cs in cliqueSizeLst:\n",
    "#         for chosenUserArr in cliqueDf[cliqueDf.cliqueSize == cs].iloc[:, :cs].values:\n",
    "#             # Throw away unneeded columns\n",
    "#             cliqueSubDf = userDf2CliqueDf(df[['user', 'comtype', 'weekday', 'timestamp', 'contactedUser']], chosenUserLst)  \n",
    "#             chosenUserLst = chosenUserArr.tolist()\n",
    "#             toPcaRaw = userDf2timebinAdjMat(cliqueSubDf, binsCalendarDay, chosenUserLst)\n",
    "#             callArgList.append((toPcaRaw, cs)) \n",
    "# \n",
    "#     call = pool.map(foo, callArgList)\n",
    "# \n",
    "# finally:\n",
    "#     pool.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mpl2]",
   "language": "python",
   "name": "conda-env-mpl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
